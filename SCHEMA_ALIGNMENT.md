# ðŸ“Š Optimized Schema - Complete Alignment Guide

## ðŸŽ¯ Schema Overview

The optimized schema uses **4 clean tables** with **zero unnecessary fields**:

```
profiles (user info)
    â†“
documents (file metadata)
    â†“
document_fields (field definitions)
    â†“
extracted_data (extraction results)
```

---

## âœ… Table 1: profiles

### Schema:
```sql
CREATE TABLE public.profiles (
  id uuid PRIMARY KEY,              -- FK to auth.users
  username text UNIQUE,              -- Auto-generated from email
  full_name text,                    -- From OAuth or signup
  avatar_url text,                   -- From OAuth provider
  created_at timestamp               -- Auto-set
);
```

### Frontend Usage:
```typescript
// lib/client.ts - No direct access
// Profile auto-created by trigger on signup

// app/profile/page.tsx (if exists)
interface Profile {
  id: string
  username: string
  full_name: string
  avatar_url: string
  created_at: string
}
```

### Edge Functions:
```typescript
// Not directly accessed by edge functions
// Used only for user info display in frontend
```

### Notes:
- âœ… Minimal fields (removed `updated_at`, `website`, `bio`)
- âœ… Auto-created on signup via trigger
- âœ… Username auto-generated from email
- âœ… Full name from OAuth or signup form

---

## âœ… Table 2: documents

### Schema:
```sql
CREATE TABLE public.documents (
  id uuid PRIMARY KEY,               -- Auto-generated
  user_id uuid NOT NULL,             -- FK to auth.users
  name text NOT NULL,                -- Document name
  storage_path text NOT NULL,        -- Path in storage bucket
  status text DEFAULT 'pending',     -- Enum: pending|processing|completed|failed
  created_at timestamp NOT NULL,     -- Auto-set
  processed_at timestamp             -- Set when completed
);
```

### Frontend Usage:
```typescript
// app/dashboard/page.tsx
interface Document {
  id: string
  name: string
  storage_path: string
  status: string
  created_at: string
  processed_at: string | null
}

// Fetch documents
const { data } = await supabase
  .from("documents")
  .select("*")
  .eq("user_id", user.id)
  .order("created_at", { ascending: false })
```

### Edge Functions:
```typescript
// process-document-backend/index.ts

// CREATE document
const { data: docData } = await supabaseClient
  .from("documents")
  .insert({
    user_id: user.id,
    name: documentName,
    storage_path: filePath,
    status: "processing"
  })
  .select()
  .single()

// UPDATE status to completed
await supabaseClient
  .from("documents")
  .update({ 
    status: "completed",
    processed_at: new Date().toISOString()
  })
  .eq("id", docId)
```

### Notes:
- âœ… `storage_path` matches edge function code
- âœ… `status` enum enforced at database level
- âœ… `processed_at` auto-updated by trigger on completion
- âœ… No unused fields like `model_id`

---

## âœ… Table 3: document_fields

### Schema:
```sql
CREATE TABLE public.document_fields (
  id uuid PRIMARY KEY,               -- Auto-generated
  document_id uuid NOT NULL,         -- FK to documents
  name text NOT NULL,                -- Field name (e.g., "InvoiceId")
  type text DEFAULT 'text',          -- Field type
  description text,                  -- Auto-generated or user-provided
  created_at timestamp NOT NULL      -- Auto-set
);
```

### Frontend Usage:
```typescript
// app/document/[id]/page.tsx

// ADD new field
const { data: fieldData } = await supabase
  .from("document_fields")
  .insert({
    document_id: documentId,
    name: newFieldName,
    type: "text",
    description: `User-added field: ${newFieldName}`
  })
  .select()
  .single()

// DELETE field
await supabase
  .from("document_fields")
  .delete()
  .eq("id", fieldId)
```

### Edge Functions:
```typescript
// process-document-backend/index.ts

// CREATE field definitions
const fields = fieldsToExtract.map((fieldName) => ({
  document_id: docId,
  name: fieldName,
  type: "text",
  description: `Auto-generated field for ${fieldName}`
}))

await supabaseClient
  .from("document_fields")
  .insert(fields)
```

### Notes:
- âœ… Stores field **definitions** only
- âœ… Actual extracted **values** in `extracted_data` table
- âœ… `type` field for future validation/formatting
- âœ… `description` for user context

---

## âœ… Table 4: extracted_data

### Schema:
```sql
CREATE TABLE public.extracted_data (
  id uuid PRIMARY KEY,               -- Auto-generated
  document_id uuid NOT NULL,         -- FK to documents
  field_id uuid NOT NULL,            -- FK to document_fields
  value text,                        -- Extracted value
  confidence numeric(5,4),           -- Azure confidence score (0-1)
  created_at timestamp NOT NULL,     -- Auto-set
  UNIQUE(document_id, field_id)      -- One value per field per document
);
```

### Frontend Usage:
```typescript
// Accessed via edge function (not directly)
// app/document/[id]/page.tsx

interface ExtractedField {
  id: string
  fieldId: string           // From document_fields
  fieldName: string         // Joined from document_fields
  fieldType: string         // Joined from document_fields
  fieldDescription: string  // Joined from document_fields
  value: string            // From extracted_data
  confidence: number | null // From extracted_data
}

// UPDATE field value
await supabase
  .from("extracted_data")
  .upsert({
    document_id: documentId,
    field_id: fieldId,
    value: newValue,
    confidence: null
  }, { onConflict: "document_id,field_id" })
```

### Edge Functions:
```typescript
// process-document-backend/index.ts

// SAVE extracted data
const dataToSave = docFields.map((field) => ({
  document_id: docId,
  field_id: field.id,
  value: extractedData[field.name]?.value || "",
  confidence: extractedData[field.name]?.confidence || null
}))

await supabaseClient
  .from("extracted_data")
  .upsert(dataToSave, { onConflict: "document_id,field_id" })

// get-extracted-data-backend/index.ts

// FETCH with JOIN
const { data } = await supabaseClient
  .from("extracted_data")
  .select(`
    id,
    value,
    confidence,
    document_fields (
      id,
      name,
      type,
      description
    )
  `)
  .eq("document_id", documentId)
```

### Notes:
- âœ… Stores actual extracted **values**
- âœ… `UNIQUE(document_id, field_id)` prevents duplicates
- âœ… `confidence` from Azure (0.0000 to 1.0000)
- âœ… Can upsert to update existing values

---

## ðŸ” Row Level Security (RLS)

### All Tables Protected:
```sql
-- Users can only access their own data
-- Enforced through foreign key to documents.user_id

profiles:         auth.uid() = id
documents:        auth.uid() = user_id
document_fields:  EXISTS (check via documents.user_id)
extracted_data:   EXISTS (check via documents.user_id)
```

### Storage Bucket:
```sql
-- Users can only access files in their folder
-- Format: user_id/filename.ext

Upload:  (storage.foldername(name))[1] = auth.uid()::text
Select:  (storage.foldername(name))[1] = auth.uid()::text
Update:  (storage.foldername(name))[1] = auth.uid()::text
Delete:  (storage.foldername(name))[1] = auth.uid()::text

-- Public read for Azure processing
Public Read: bucket_id = 'documents'
```

---

## ðŸ”„ Complete Data Flow

### 1. User Signup
```
User signs up with email/OAuth
    â†“
Trigger: on_auth_user_created
    â†“
INSERT INTO profiles (id, username, full_name, avatar_url)
    â†“
Profile created âœ…
```

### 2. Upload Document
```
Frontend: uploadDocument(file, name)
    â†“
Edge Function: upload-document-backend
    â†“
Generate signed URL for storage
    â†“
Return: { filePath: "user_id/file.pdf", publicUrl, uploadUrl }
    â†“
Frontend: PUT file to uploadUrl
    â†“
File stored in storage bucket âœ…
```

### 3. Process Document
```
Frontend: processDocument({ filePath, publicUrl, fieldsToExtract })
    â†“
Edge Function: process-document-backend
    â†“
Step 1: INSERT INTO documents (user_id, name, storage_path, status='processing')
    â†“
Step 2: INSERT INTO document_fields (document_id, name, type, description)
    â†“
Step 3: Call Azure Document Intelligence API
    â†“
Step 4: Poll for results (max 60 seconds)
    â†“
Step 5: INSERT INTO extracted_data (document_id, field_id, value, confidence)
    â†“
Step 6: UPDATE documents SET status='completed', processed_at=NOW()
    â†“
Trigger: document_processed_at_trigger (auto-sets processed_at)
    â†“
Processing complete âœ…
```

### 4. View Results
```
Frontend: getExtractedData(documentId)
    â†“
Edge Function: get-extracted-data-backend
    â†“
SELECT * FROM documents WHERE id = documentId
    â†“
SELECT extracted_data.* JOIN document_fields
    â†“
Return: { document, extractedFields: [...] }
    â†“
Frontend displays fields with values and confidence âœ…
```

### 5. Manual Field Operations
```
ADD FIELD:
Frontend â†’ INSERT INTO document_fields
         â†’ Show in UI

EDIT VALUE:
Frontend â†’ UPSERT INTO extracted_data
         â†’ Update UI

DELETE FIELD:
Frontend â†’ DELETE FROM document_fields
         â†’ CASCADE deletes from extracted_data
         â†’ Update UI
```

---

## ðŸ“‹ Schema Optimization Decisions

### âœ… Removed Unnecessary Fields:

**From profiles:**
- âŒ `updated_at` (not used anywhere)
- âŒ `website` (not needed for document extraction)
- âŒ `bio` (not needed for document extraction)

**From documents:**
- âŒ `model_id` (hardcoded as "prebuilt-invoice" in edge function)
- âŒ `file_url` (replaced with `storage_path`)
- âŒ `public_url` (generated dynamically when needed)

**Kept Essential Fields:**
- âœ… `storage_path` - Required for file access
- âœ… `status` - Required for tracking processing state
- âœ… `processed_at` - Required for completion tracking
- âœ… `confidence` - Required for data quality metrics

### âœ… Optimized Constraints:

```sql
-- Enum constraint for document status
CHECK (status IN ('pending', 'processing', 'completed', 'failed'))

-- Username minimum length
CHECK (char_length(username) >= 3)

-- Confidence precision
numeric(5,4)  -- e.g., 0.9876 (4 decimal places)

-- Unique constraint for extracted data
UNIQUE(document_id, field_id)  -- Prevents duplicates, enables upsert
```

### âœ… Optimized Triggers:

```sql
-- Auto-create profile on signup
on_auth_user_created â†’ handle_new_user()

-- Auto-set processed_at when completed
document_processed_at_trigger â†’ update_document_processed_at()
```

---

## ðŸš€ Deployment Steps

### 1. Run the Optimized Schema
```bash
# Go to Supabase SQL Editor
https://supabase.com/dashboard/project/lputifqvrradmfedheov/sql/new

# Copy and paste OPTIMIZED_SCHEMA.sql
# Click RUN
```

### 2. Verify Setup
Check the output shows:
```
status: "Schema Setup Complete!"
profiles: X
documents: X
document_fields: X
extracted_data: X
```

### 3. Test Frontend
```bash
npm run dev
```

### 4. Test Full Flow
1. Sign up â†’ Profile auto-created âœ…
2. Upload document â†’ File stored âœ…
3. Process â†’ Data extracted âœ…
4. View details â†’ Fields displayed âœ…
5. Add field â†’ Field created âœ…
6. Edit value â†’ Value updated âœ…
7. Delete field â†’ Field removed âœ…

---

## âœ… Perfect Alignment Summary

| Component | Table Used | Columns Used | Status |
|-----------|-----------|--------------|--------|
| **Signup** | profiles | id, username, full_name, avatar_url | âœ… Aligned |
| **Upload** | Storage | bucket_id, name | âœ… Aligned |
| **Process (Create)** | documents | user_id, name, storage_path, status | âœ… Aligned |
| **Process (Fields)** | document_fields | document_id, name, type, description | âœ… Aligned |
| **Process (Extract)** | extracted_data | document_id, field_id, value, confidence | âœ… Aligned |
| **Process (Complete)** | documents | status, processed_at | âœ… Aligned |
| **View Dashboard** | documents | id, name, storage_path, status, created_at | âœ… Aligned |
| **View Details** | extracted_data + document_fields | All fields via JOIN | âœ… Aligned |
| **Add Field** | document_fields | document_id, name, type, description | âœ… Aligned |
| **Edit Value** | extracted_data | document_id, field_id, value | âœ… Aligned |
| **Delete Field** | document_fields + extracted_data | CASCADE delete | âœ… Aligned |

---

## ðŸŽ‰ Result

**Zero unused fields**  
**Zero schema mismatches**  
**100% frontend alignment**  
**100% edge function alignment**  
**Production ready** âœ…
